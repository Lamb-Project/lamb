# API key for authentication
LAMB_API_KEY=0p3n-w3bu!

# Default embeddings model configuration
# These variables are used when 'default' is specified in collection creation

# Embeddings model to use
EMBEDDINGS_MODEL=nomic-embed-text

# Vendor/provider of embeddings ('ollama', 'local', 'openai')
EMBEDDINGS_VENDOR=ollama

# API endpoint for Ollama (required for Ollama embeddings)
EMBEDDINGS_ENDPOINT=http://localhost:11434/api/embeddings

# API key (if required by the vendor, e.g., for OpenAI)
EMBEDDINGS_APIKEY=

# URL of the home page
HOME_URL=https://yourdomain.com/kb/

# For OpenAI embedding models:
# EMBEDDINGS_MODEL=text-embedding-3-small
# EMBEDDINGS_VENDOR=openai
# EMBEDDINGS_APIKEY=your-openai-key-here

# Firecrawl configuration for URL ingestion plugin
# For self-hosted Firecrawl instance running on the host machine
# Use host.docker.internal to access services on the host from inside Docker
FIRECRAWL_API_URL=http://host.docker.internal:3002
# For cloud Firecrawl service, uncomment and set your API key:
# FIRECRAWL_API_URL=https://api.firecrawl.dev
# FIRECRAWL_API_KEY=your-firecrawl-api-key-here

# LangSmith Evaluation Configuration
API_BASE_URL=http://localhost:9099
JWT_TOKEN=your-jwt-token-here
ASSISTANT_ID=1 # your-assistant-id-here
DATASET_NAME=your-dataset-name
EVALUATOR_MODEL=gpt-4.1

# Logging
# LAMB KB webapp-specific log level (falls back to GLOBAL_LOG_LEVEL if unset)
LAMB_KB_LOG_LEVEL=WARNING