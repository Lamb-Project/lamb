[
    {
        "number": 1,
        "title": "Entrevista experto etico social",
        "page": 1,
        "text": "Entrevista a experto ética y aspectos sociales pag 1  \n \nTenemos una empresa que se llama Tesla, y esta empresa ya hace unos años ha decidido que quieren coger y pivotar hacia un nuevo tipo de \nnegocio, que es la fabricación de robots antropomórficos, lo que podríamos llamar androides. \nEllos han diseñado un robot que se llama Optimus. \nLa idea de Tesla es aprovechar su capacidad de fabricación de vehículos, de coches, y la idea es que la plataforma tecnológica sobre la cual \nconstruyen el robot es la plataforma de fabricación de coches. \nHe sabido desde hace poco que la empresa Hyundai ha cogido y ha comprado a Boston Dynamics, que es la empresa líder en investigación \nque hace aquellos robots que hacen Parkour, los robots Atlas. \nEntonces Hyundai ha comprado esto. \nEs para decir, de alguna manera, las empresas automovilísticas que hacen vehículos eléctricos han visto que el tipo de ascensores y de \nmotores y de almacenamiento y prácticamente la fabricación de los coches es compatible con la fabricación de estos robots y el problema \nprecisamente es no solo desarrollar el bicho, sino cómo esto se fabrica a escala. \nLa idea de ellos es que son robots que deben convivir en los entornos donde hay humanos. \nEs decir, un robot industrial no tiene por qué parecerse a un humano porque tiene que hacer cosas, como hacer de prensa o hacer de sombras \narticuladas, pero en este caso el argumento es que muchos de nuestros entornos están diseñados para los seres humanos, las escaleras son de \nanchura y los escalones son para humanos, las cosas están a la altura de las manos y de la cintura de una cocina o una línea de fabricación \ndonde haya personas o una máquina de coser. \nEstán pensadas para ser operadas por humanos y por lo tanto lo que ellos dicen es que si conseguimos un robot que tenga las dimensiones y \nuna motricidad y capacidad de fuerza similar al orden de un ser humano, entonces podrá operar y hacer muchas tareas que ahora están \nhaciendo los humanos, algunas de ellas peligrosas, algunas de ellas tediosas. \nY además, en el momento en que enseñamos a una máquina a hacer el trabajo, este aprendizaje lo podemos transmitir a toda la flota. \nPor lo tanto, tenemos una escalabilidad. \nLas promesas, evidentemente, ya sabemos que Elon Musk siempre hace unas promesas, hace overpromise, pero lo que pasa es que al final \nacaba haciendo el delivery. \nEs decir, Elon Musk, prácticamente todas las promesas que ha hecho, prácticamente la única que no ha llegado a cumplir es la del autopilot, \nel autopilot completo, el full self-drive de los coches, pero en general cumple sus propuestas. \nLo que pasa es que unos años después de lo que él ha dicho, él siempre es muy optimista en el tiempo en que lo conseguirá, pero acaba \nconsiguiendo cosas, como el coche eléctrico o incluso llegar a los precios de todos los vehículos. \nEl Tesla 3 está al precio que él había dicho y tiene las prestaciones que él había dicho que tendría y va iterando. \nEs muy ambicioso y simplemente lo que hace es que tarda un poco. \nÉl quiere conseguir que el robot este tenga un coste de puesta a precio de venta sin impuestos de aproximadamente 25.000 dólares. \nSi podemos calcular que si puede, por ejemplo, sustituir el trabajo de un trabajador, por ejemplo un trabajador de almacén, al año cobra \nmucho más de 25.000 dólares y su mantenimiento es mucho más elevado, con lo cual, digamos, tenemos bastante bien calculado cuáles son \nlos precios que serían ofreciendo un producto atractivo. \nEntonces, lo que nos tendríamos que preguntar aquí es decir, qué dilemas éticos y problemas éticos nos empezamos a encontrar con esto. \n \nDe entrada, sí que como dices Elon Musk tiene una cosa, que es que el tío yo pienso que acierta en ir hacia problemáticas que tienen \nimpacto. \nTiene también ese punto un poquito visionario, que es el ocultante en otros aspectos, que también eso lo tiene, la verdad sí que se lo tengo \nque reconocer. \nPorque, por ejemplo, el Ramón López de Mantares, como hablábamos hace un rato, siempre ha dicho que una inteligencia artificial que no \ntenga un cuerpo y no podrá llegar nunca a ser una IA general, ese sueño de la IA general, necesita de un cuerpo y por tanto entra en la \nrobótica. \nHabla del embodiment. \nEl embodiment, efectivamente. \nLa palabra es curiosa. \nSí, porque me gusta, de hecho, una cosa que he escrito hace poco, me gusta la palabra, en castellano era \"encuerpar\", porque no hay una \npalabra... \nSería incorporación pero que tiene una semántica diferente. \nSí, pero podemos decir \"encarnación\", que es la encarnación de un avatar. \nClaro, y tiene que ver con \"carn\" y de hecho los robots no son de carne. \nDe hecho lo discutía como lingüista, eso de la encarnación como traducción. \nPor tanto, en catalán como en castellano, yo pienso que por qué no, nos inventamos palabras... \nIncorporación sería la palabra, o sea, si cogiéramos las raíces semánticas, los lexemas serían los correctos. \nPero como ya hay otra... \nYa hay otra, es simplemente añadir tu cuerpo a otra estructura, como incorporarte a una organización. \nSí, sí, sí. \nBueno, dejando de lado la lingüística, que me encanta, yo creo que el \"riesgo del optimus\"... \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n",
        "kind": "online_pdf",
        "filename": "optimus-e-etico-social.pdf",
        "url": "https://data.llmprimer.com/optimus/optimus-e-etico-social.pdf#page=1"
    },
    {
        "number": 2,
        "title": "Entrevista experto etico social",
        "page": 2,
        "text": " \nEntrevista a experto ética y aspectos sociales pag 2  \n \nA ver, para empezar hay uno que es fundamental, que es la seguridad física. \nEl tema de los posibles accidentes de la máquina. \nY aquí recuerdo, por ejemplo, a la Carme Torres, con todos los robots asistenciales, que ya se envuelven en el IRI con su grupo de \ninvestigación, hay toda esa línea de decir \"lo principal es la seguridad\". \nPor ejemplo, imagina... \nMe pongo en el caso de los robots asistenciales que están desarrollando en el IRI, del OPC, vinculado al OPC. \nCuando tú le das de comer a una persona, puedes encontrar que la persona ofrece cierta resistencia. \nQue imagínate tú, te pones una cuchara... \nEstoy pensando en esto, eh? \nPor ejemplo... \nCualquier persona que haya dado de comer a un niño pequeño, a meses, coger un niño de un año y darle una papilla. \nEs todo un reto. \nEs un reto muy complejo. \nY la máquina podría ser que, imagínate, que fuerza en un momento dado y le pega un viaje a la boca a la persona. \nQuién dice esto dice, ahora pensando en otros robots del IRI, esos robots que doblan ropa, que en un momento dado tú pasas por allí y la \nmáquina, con la fuerza que tiene, te pega un golpe, un viaje, a una persona que está pasando por alrededor. \nQuiero decir, los accidentes... \nPara mí, la ciudad física de los robots es una cosa que, bueno, ya los que están en robótica ya lo saben, es quizás el primer aspecto a \nconsiderar, ¿no? \nBueno, aquí nos encontramos, digamos, con las leyes... \nQuizás sería interesante recordar las tres leyes de Simov, que es que un robot... \nLa primera ley es que un robot no puede, por su acción o por su inacción, hacer que un humano sufra daño. \nDespués, la otra es que un robot debe obedecer las órdenes del humano autorizado para darle órdenes, siempre que eso no contravenga la \nprimera ley. \nY la tercera es que un robot debe preservar su integridad física y estructural siempre que no contravenga la primera o la segunda ley. \nEvidentemente, claro, solo en los escenarios, las interacciones y dilemas que supone la imposibilidad de cumplir estas directrices, de \ncumplirlas todas, es decir, claro, imagínate, en el momento que tú tienes dos personas a punto de sufrir daño, aquí salvas, ya tenía aquí un \nproblema... \nCorrecto, en los dilemas del \"moral myth\", que se han amparado con los debates con el coche autónomo, que ya sufrió un poco Elon Musk \ncon Tesla, hay todo el tema de... \nHay aquella web del \"moral MIT\"... \nSí, sí, de \"moral machine\". \nAquí te llevas por delante, o qué preservas? \nLa vida de los tripulantes, de las personas que van en el vehículo, o de los que están pasando en verde en un semáforo? \nPor mucho que nos disguste, en un producto comercial, al final es decir si el vehículo preserva la vida de los que están afuera respecto a los \nque están adentro, no la venderás, al menos no... \nLa Mono la querrá, seguramente. \nPero hay otro tema que se había planteado, no sé si tú lo habías escuchado, pero con el tema de... \nSe planteaba que el Optimus podría ser un vigilante, ¿no? \nY aquí, o sea, hacer de vigilante pasivo, en el sentido que... podría... hacer como de alarma, en un momento dado... \nUna cámara de seguridad móvil. \nCorrecto. \nY también recopilar datos personales sin consentimiento... \nQuiero decir, todo el tema del consentimiento de datos, lo tendría también esta vertiente de la cámara? \nBueno, pero en este caso eso está resuelto, porque si yo pongo una cámara en un lugar, pues hay unas normativas, y quizás tengo que poner \nunas noticias, si entras en este espacio y estás aceptando las normas... \nSi yo entro dentro del Mercadona y hay cámaras en el Mercadona, seguramente hay un cartel en algún lugar del Mercadona que dice que mi \ncara será grabada por propósitos de seguridad, y que esa imagen al cabo de ciertos días será destruida y que no se vinculará... \nPero Marc, hay un tema, que es que la cámara es un elemento pasivo y el Optimus puede ser activo. \nEs decir, si puede avisar de forma automática, como también parece que se había planteado, a sistemas, digamos, a una central de \nseguridad... \nPero eso lo hacen también... \nO sea, yo tengo una cámara mía, en el jardín de casa, que lo que hace es saber cuáles son las características de los habitantes de la casa, y en \nciertas horas, si viene una persona que no está autorizada, me notificará a mí y se puede conectar contra la central de alarmas. \nEso lo hacen cámaras hoy en día ya. \nO sea, que es un dilema, pero hay histerias. \nOtra cosa es que el Optimus pasee por la calle. \nSí, pero si ahora el robot este tú lo habilitas para que te defienda, le puedes decir una claque a un que se ha acercado... \nTendrá capacidad de agresión, este robot? \nEn principio no está incorporado. \nMe gusta el \"en principio\". \nNo está incorporado todo. \nY además, creo que los niveles de potencia de los actuadores están al orden de magnitud de una persona. \nNo estamos dando fuerza sobrehumana. \nAl final, es un pistón neumático que te puede levantar un par de toneladas y lo puedes usar para levantar el coche y cambiar ruedas. \nPero si no tuviéramos un robot militar adaptado a la docencia, en un mundo doméstico... \nEso ya sería otro caso. \nNo es el caso de lo que estamos. \n \n \n",
        "kind": "online_pdf",
        "filename": "optimus-e-etico-social.pdf",
        "url": "https://data.llmprimer.com/optimus/optimus-e-etico-social.pdf#page=2"
    },
    {
        "number": 3,
        "title": "Entrevista experto etico social",
        "page": 3,
        "text": " \n \nEntrevista a experto ética y aspectos sociales pag 3  \n \nLo que estamos es hablando de un robot que, además, poco a poco, sus habilidades se van desarrollando muy poco a poco. \nEl otro día enseñaban cómo agarrar un huevo y no romperlo. \nAgarrar un huevo, cambiarlo de mano y volverlo a poner. \nEra como una de las grandes cosas. \nNo, eso es un reto con el embodiment. \nYa se han visto robots similares que están enhebrando agujas. \nSí, sí. \nEsos de robótica asistencial van en esa línea de alimentar gente y de interactuar con las personas. \nPero, bueno, volviendo al tema... \nHemos dicho por ahora seguridad física, temas de privacidad de datos. \nYo pienso que es problemático, aunque se pueda resolver, porque si no supongo que no nos lo plantearíamos. \nSi no fuera viable en el mercado, eso lo resolverán. \nRespecto a otro tema que a mí me preocupa, que antes comentábamos también antes de la grabación, es el tema de los sesgos, de los \nentrenamientos. \nEs decir, que los sistemas de reconocimiento funcionen bien con personas de diferentes etnias, que el tipo de sesgos que incorpore la \nmáquina según el entrenamiento será inevitable y se tendrán que ir puliendo, que también se mejorará, eso no será problemático. \nPero otra cosa que también comentábamos antes, el tema de los errores de aprendizaje, que los sistemas no se entrenen correctamente y, por \ntanto, puedan cometer errores. \nSupongo que este robot tendrá un amo que será el responsable de las acciones del robot en caso de que la pifie, que haya errores. \nEste es un problema grave. \nEste es un problema grave que también pasa, por ejemplo, con los sistemas de autoconducción. \nEs decir, si el sistema comete un error, de quién es culpa? \nDe la persona que le dijo que vaya a cierto lugar? \nDe la empresa? \nDe la empresa de seguros? \nHay un vacío que como sociedad tenemos que resolver este tipo de cuestiones. \nAdemás, hay otro problema, y es que así como la informática hasta hace poco eran sistemas deterministas, es decir, por ejemplo, tú coges un \nsistema... \nMi coche tiene 11 años y tiene un sistema de radar en el morro. \nEntonces, si detecta que hay un obstáculo en el camino del coche y que se mueve a una velocidad suficientemente rápida y el diferencial de \nvelocidad con mi coche es bastante grande, pita. \nLa acción es que pita y yo tengo que tomar la decisión. \nHay versiones de coches ensamblados que tienen ese sistema que lo que hace es que el coche frena. \nFrena solo, sí, sí. \nEl coche frena solo, pero hay muchos falsos positivos. \nA veces, un bulto de esos que hay en la carretera ha hecho que el coche pite, o si yo me acerco hacia una curva un poco demasiado cerrada y \nno he frenado suficiente tiempo, pitará y está dentro... \nEs decir, hay falsos positivos, pero de alguna manera es si hay una señal... \nEs un IF, es una acción determinista. \nSi hay esa señal, tomo esa decisión, pito. \nEn cambio, cuando estoy trabajando con sistemas, digamos, basados en redes neuronales, toda la familia, desde los modelos generativos a \ncualquier otro tipo de modelo, estamos basados en modelos probabilísticos. \nY precisamente la funcionalidad que tienen se basa en que es un sistema estocástico y, por tanto, no podemos asegurar cómo se comportará. \nYa, ya. \nYo creo que aquí hay un tema importante que es el hecho de que puede haber imprevistos y cosas que no estén programadas y que la \nmáquina... \nPorque, como dices, la conducción es un buen ejemplo. \nYo me encontré con un vehículo de alquiler que llevaba todos los sensores habidos y por haber, que en un momento dado pasó un pájaro un \npoco grande, cerca, y lo detectó como obstáculo detectado y hizo una frenada en la autopista, que era como... \n¡Ostras! \nFue un susto. \nSolo hizo como una frenada y, bueno, fue como una alarma en el vehículo. \nPero ha hecho una palabra que me ha hecho pensar, que es \"seguro\". \nYo supongo que por normativa habrá que hacer toda una norma de... \nEstas máquinas tendrán que estar aseguradas y, en el sentido que entiendo que tiene que haber una responsabilidad y, en ese sentido, los \naseguradores intentarán que, ostras, si hay una pifia, mira, tú pagas tanto tú y, por tanto, yo asumiré los riesgos derivados de daños que \npueda hacer el mal que pueda hacer esta máquina. \nDespués hay otro tema, también, que está ligado con la máquina y los masajes, pero también con temas de seguridad, que son los \nciberataques, los ciberataques que pueda sufrir la máquina. \nO sea, si pueden tomar el control de esta máquina desde fuera, la pueden... \nEl problema de la seguridad informática, en este caso, la ciberseguridad... \nQué te voy a explicar, Anna, tú? \nQuiero decir que esto... \nDe repente, la ciberseguridad entra a otro nivel. \nPor ejemplo, sabemos, con el tema de los vehículos, cuando se empezaron a coger y a poner... \nA ver, una cosa tan sencilla como poder abrir el coche de manera remota... \nA ver, tú estás enviando una señal y alguien más puede copiar esa señal y, si sabemos qué tecnología es, a partir de esa asignatura, alguien \npuede imitar tu firma criptográfica e intentar abrir y hacerse con el control de tu coche. \n",
        "kind": "online_pdf",
        "filename": "optimus-e-etico-social.pdf",
        "url": "https://data.llmprimer.com/optimus/optimus-e-etico-social.pdf#page=3"
    },
    {
        "number": 4,
        "title": "Entrevista experto etico social",
        "page": 4,
        "text": "De hecho, los primeros coches que incorporaron este tipo de tecnologías fueron coches de alta gama, que eran muy apetecibles para robar, y \nveíamos que en Porsches y Ferraris eran robados con más facilidad que otros coches que se abrían con una llave. \nClaro, claro, y aquí, si te has gastado 25.000 dólares que decías antes con eso que te lo roben, puede ser un poco... \nEntrevista a experto ética y aspectos sociales pag 4 \n \nPero claro, si el sistema de seguridad, si yo me hago con un coche, por ejemplo, es un ordenador al final, si me hago con control de eso, \npuedo afectar los \"frames\" y el acelerador y te puedo causar un accidente. \nEs decir, las consecuencias de un error son más grandes. \nY en el caso de Tinder, pues eso es un robot corriendo por tu casa, que sea un poco más grande que un Roomba, de repente puedo tener un \ninstrumento para causar problemas. \nEs que se puede volver en un arma, porque en un momento dado tú puedes intentar modificar esa máquina una vez la has \"hackeado\", la has \npirateado de alguna manera. \nEso también es otra cosa que... \nAquí abrimos? \nSí, dices, dices. \nNo, que relacionado con eso, también creo que supongo que la máquina contará que puede haber, por ejemplo, diferentes tipos de accesos. \nImagina que interactúo con niños o con gente independiente. \nO sea, yo creo que la programación puede ser compleja en el sentido que los usuarios humanos son muy diversos. \nNosotros, en general, nos adaptamos a la interacción social con los humanos, ¿no? \nY lo hacemos de una forma que desde que somos pequeños, no sé... \nFíjate que a veces un niño muy pequeño, cuando se acerca a una persona mayor, si la ve en una silla de ruedas, ya actúa de otra manera, \n¿no? \nDiferente. \nY eso yo creo que implica una complejidad que no dudo que se pueda programar, pero pero se me hace, como te diría, que la máquina se \npueda usar en usos muy diversos con la interacción humana, más allá de cargar y descargar, pensando en niños pequeños y en personas \ndependientes, sobre todo, creo que eso también es un reto. \nY en compañía, porque al final este tipo de tecnología que al final en la que estamos hablando, pues, de actuadores mecánicos y un cuerpo \nque se puede mover, pero si eso tú después lo combinas con una colección de sistemas generativos, con voz y además con... a ver, los \nmodelos de lenguaje, que sabemos que tienen capacidades a hacer análisis de sentimiento y tienen capacidad de dar respuestas, por ejemplo, \nactualmente hay gente que están usando modelos de lenguaje diseñados para comportarse como terapeutas y hay gente que prefiere estos \nmodelos de lenguaje como psicoterapeutas que no personas, porque se pueden abrir más en este modelo. \nPues claro, imagina tener todos los elementos para de repente crear un compañero o una compañera virtual sin abrir el menor al melón, \ndigamos, de los juguetes sexuales que ya sería un melón. \nBueno, bueno, si abrimos el melón de los juguetes sexuales ya que estamos a otro nivel, yo creo, también pero es posible que llegue. \nPorque es la finalización, también. \nClaro, es un paso, quiero decir que... \nY ha sido un vector de adopción de muchas tecnologías como el vídeo o la misma internet. \nClaro, aquí comentas cosas interesantes porque hay la cuestión de, aparte de la interacción física, táctil, digamos, háptica, tenemos la voz, \ntenemos la posibilidad de incorporar el nuevo reproductor de vídeo y todo eso ligado con unas funcionalidades que podrían generar cierta \ndependencia, digamos, tecnológica. \nNo diríamos dependencia emocional o sexual, que sería otro nivel, pero sí que hay una... \nSobran muchos aspectos a las relaciones que establecimos con las máquinas y en ese sentido también eso implica ciertos dilemas, yo creo \nque como mínimo éticos o, incluso, morales, en algún punto. \nSuponiendo que esto lo dijéramos, evidentemente entiendo que lo que se dibuja aquí es que se empezarán a abrir ciertos entornos en los que \nestos robots tengan cabida. \nO sea, quizás podríamos decir, por ejemplo, empezamos a usarlo de Mozos de Almacén, y trabajos que, por ejemplo, son duros. \nPor ejemplo, actualmente los Mozos de Almacén que tienen que trabajar en almacenes robotizados son personas que tienen que estar \nconviviendo con máquinas muy potentes que a veces se mueven muy de prisa y es peligroso. \nEn cambio, podrías sustituir esa última parte de los trabajadores de Almacén que, de repente, fueran aparatos de tipo óptimus. \nY en este caso no hay tanta interacción con personas, sino que estás sustituyendo... \nO, por ejemplo, a ver, cuando hubo el tema de Chernóbil y de Fukushima, sobre todo en Fukushima, se intentaron usar robots que cayeron y \nse rompieron estrepitosamente. \nPero, quizás tienes una mina donde se tiene que bajar un lugar muy peligroso en vez de enviar una persona, puedes enviar un óptimus. \nSí, sí, claro, claro. \nEso pasó en Fukushima, que los japoneses se vieron que de hecho los incorporaron, recordando tecnología americana. \nEso fue un poco una humillación nacional, porque Japón que es... \nSe dieron cuenta de que no tenían robots, cogieron robots militares americanos para hacer las tareas de entrar en las zonas radiadas porque \ntenían muchos robots de juguete y de ocio, pero no tenían robots serios para entrar en las peores condiciones, digamos, lo digo de memoria, \nrecordando, pero... \nAhora, hace unos 10 años, en la Casa Asia, vino el ministro de Ciencia y Tecnología de Japón a dar una conferencia y, básicamente, él \nexplicó que Japón tiene una política de inmigración muy dura, una política de inmigración muy dura, como cultura son muy cerrados, y en \nese caso son muy clasistas respecto a los forasteros, te tratan con mucha educación y esa educación también es una barrera social, es decir, te \ntratan con tanta educación que aquello es que tampoco podemos tener una relación significativa. \nY, como aquello es claro, como no tienen inmigración y les está envejeciendo la población, no tienen a quién lavar el culo, los viejos, \nbásicamente. \nY entonces, lo que ellos hacían de apuesta ya no eran en robótica industrial, que eso es, digamos, ellos entendían que la robótica industrial es \nla robótica industrial Toyota y todo eso, es que ya dominan, pero querían hacer un corte, digamos, en el robot más \"tow\", doméstico, el \nasistencial, el buset, el robot abrazable, las caras, esas más o menos amables, ese tipo de cosas que ellos han estado trabajando, mientras que \nlos americanos han estado, digamos, a hacer cosas como robots que desactivan bombas y cosas de ese estilo. \nSí, sí, aquí hay una... \nVolviendo al tema, creo que el tema de la dependencia emocional o de la relación antropomorfizada, digamos, con los robots genera \ntambién otros dilemas, porque en serio sentido, yo me imaginaba más una primera entrada robótica más ligada a sistemas tipo exoesqueleto, \nmás integrado con las personas, de manera que fuera como fueran robots complementarios a la, por ejemplo, a la biomecánica humana. \n",
        "kind": "online_pdf",
        "filename": "optimus-e-etico-social.pdf",
        "url": "https://data.llmprimer.com/optimus/optimus-e-etico-social.pdf#page=4"
    },
    {
        "number": 5,
        "title": "Entrevista experto etico social",
        "page": 5,
        "text": "Aumentación. \nAumentación, efectivamente. \nLos mecánicos. \nEn término. \nEntrevista a experto ética y aspectos sociales pag 5 \n \nMás que un óptimus como un elemento independiente, pero el M.A.S.C. parece que va más por ahí, por la idea. \nEl Musk está jugando a todas las... a todos los terrenos de juego, porque ayer enseñaban ya los de Neuralink, enseñaban a un señor \ntetrapléjico que lo habían operado con el Neuralink y el señor tenía una silla que controlaba con la mente y controlaba, y de él decía que \ncontrolaba con perfecta precisión el mouse en un ordenador y podía teclear, o sea, solo pensando, estaban desarrollando eso, o sea, el vídeo \nque enviaron es de aquello, con lo cual dices, están como jugando a todos los... a todos los campos de juego. \nTú crees que puede haber problemas, digamos, éticos en este caso, digamos, como sociedad tenemos que decidir si queremos renunciar \nhasta cuántas tareas hechas por humanos tenemos que renunciar y puede haber como un rechazo de este tipo de tecnologías ya simplemente \ncomo un rechazo, o sea, no queremos este tipo de tecnologías en este país, Barcelona no queremos Ubers. \nBueno, seguramente yo estoy de acuerdo con que hay un rechazo personal hacia ciertas tareas que creo que la gente no se dejará de forma \ntan fácil que las haga una máquina, ya no es por el impacto, digamos, laboral que pueda tener, tipo el conflicto entre Uber y taxis en \nBarcelona, pero quiero decir de competencia por el inicio laboral, eso puede ser un punto de conflicto, sino si recuerdas la película de \n\"Robot and Frank\", como la estábamos diciendo en español, de aquel robot asistencial para una persona mayor, Frank... \nEso es una película que está muy bien, yo te la recomiendo porque incorpora ese punto de una sociedad futura donde se le lleva un robot \nasistencial a una persona mayor que ya empieza a tener cierta demencia, y allí genera ese vínculo de una banda... \nUna relación. \nClaro, una relación, pero al principio de entrada la persona mayor tiene un rechazo muy grande que para una máquina sea la que la ayude y \nno vengan las hijas, que no tienen tiempo y dice \"mira, y es más barato que...\" \nClaro, y es más barato que pagar a una persona. \nAquí podría pasar que si esta máquina tiene un precio de alguna manera y hace ciertas tareas que se reviente el mercado en un momento \ndado y se diga \"yo me ofrezco como humano, que hago más cosas, pero tengo que ser más barato que la máquina\". \nO sea, la máquina puede ir... \nPrimero tendrá un precio que será caro, seguramente será un capricho para ricos, creo, pero después a medida que baje el precio habrá ese \nconflicto entre las prestaciones que hace la persona, las prestaciones de la máquina, la persona, quiero decir, el empleador doméstico, por \nentenderlo. \nPero fíjate que aquí en Com2Go hay una divergencia en las dos opciones que tú decías. \nO sea, si vamos por el camino del Optimus, del robot asistencial, evidentemente si hay una persona que ya no tiene ningún tipo de capacidad \nde valerse por sí misma porque tiene problemas mentales, en ese caso es que seguramente no la tienes que dejar sola en un robot, debería \nestar acompañada de personas, pero si tú tienes, por ejemplo, una persona que empieza a tener problemas de movilidad y que tiene dificultad \nen vestirse y ese tipo de cosas, quizás lo que puedes hacer es dotarle de ciertos servos en las rodillas, en las articulaciones, que le ayuden a \nvolver a tener agilidad, incluso que esos servos le hagan una especie como de fisioterapia para que se mueva más. \nEntonces lo que estás haciendo es que esa persona con los servos, de repente, se puede volver a integrar a la sociedad y puede ir a comprar el \npan y puede salir y en vez de estar hablando con un robot en casa... \nEl tema ya hace años que cuaja, porque de hecho mi mujer es fisioterapeuta y hace años, cuando ella ejercía en los 90 del siglo pasado, \nempezaron a entrar en los kinetics y en esas máquinas que, por ejemplo, te hacen flexión del knee con unos ángulos concretos... \nPara ti doblar una rodilla y hacer 100 repeticiones a 90 grados, tú dejas a la persona en la máquina y la máquina le hace esa tarea, mientras el \nhumano hace tareas que la máquina no hace, como por ejemplo hacer masaje al mismo tiempo... \nPor tanto, seguramente yo pienso que el futuro es de la hibridación entre máquina y humano para las tareas. \nEl hecho de que el humano hará trabajos que la máquina no puede hacer y, por tanto, tendrá que haber un asistente humano. \nYo creo que aún eso de liberar a la gente que se puede pagar asistentes domésticos, pues pienso que los asistentes domésticos aún tienen \nmucho recorrido, pero en un momento dado tú puedes dejar a una persona... \nTienes una residencia donde hay muchísima gente a atender. \nPues la idea es que si un trabajo manual y mecánico como si la persona se deja dar de comer a una persona o hacerle unas repeticiones de \nunos movimientos, eso si se puede automatizar y hacerlo con un robot seguramente es muy bueno porque libera al humano para hacer otras \ntareas que la máquina no hace. \nO si tomas a una persona que tiene problemas de rodillas, si le pones un servo en la rodilla de alrededor para que la persona se pueda \nempollar... \nHay asistentes. \nEl Quinetec. \nEs el Quinetec. \nTiene más de 30 años. \nY precisamente ese tipo de máquinas se introdujeron mucho en los centros asistenciales porque permitían que los fisios hicieran otras tareas \ny, bueno, por qué no, quizás liberar... \nYo estoy hablando de rehabilitación. \nYo estoy diciendo de ir a comprar el pan. \nEs normal. \nEs decir, tú te pones una rodillera, digamos yo, por ejemplo, me lesioné la rodilla este enero y he estado llevando una rodillera de neopreno. \nEn vez de una rodillera de neopreno, algo mucho más complejo que me permita moverme con mi rango de movimiento y que, además, \nincluso pueda ir sintiendo hasta qué punto tiene que dejar de apoyarme para que yo pueda ir recuperando mi movilidad y, de repente, si \ntienes a una persona que le tiemblan las manos, puedes tener algún otro tipo de... \nHay muchos tipos de ayudas y permiten que las personas se valgan por sí mismas. \nDe repente, no es lo mismo una persona sentada en una silla de ruedas que una persona que quizás camina un poco raro de golpe pero que \npuede ir a comprar el pan, que puede subir escaleras, que puede hacer cosas, que puede cocinar... \nEn vez de... \nO sea, de alguna manera, hay como un camino, digamos, que es empoderar a las personas, manteniéndoles la movilidad, recordándoles las \ncosas que tengan problemas de memoria o simplemente incorporar en alguna gente automático y convertirlos en personas, aunque sean \nartificiales. \n",
        "kind": "online_pdf",
        "filename": "optimus-e-etico-social.pdf",
        "url": "https://data.llmprimer.com/optimus/optimus-e-etico-social.pdf#page=5"
    },
    {
        "number": 6,
        "title": "Entrevista experto etico social",
        "page": 6,
        "text": "Y que sean inteligentes o no, es igual si son inteligencias artificiales o no, lo que pasa es que actúan como individuos en sus interacciones \ncon las personas. \nY eso, de repente, lo introduces en la sociedad y genera un impacto en la cultura importantísimo. \nSí, sí. \nYo creo que aquí... \n \nEntrevista a experto ética y aspectos sociales pag 6  \n \n \nO sea, al final, si vamos a los grandes temas de la IA, si recuerdas la declaración de Barcelona de 2017, el primer principio sería el de \nprudencia y, en ese sentido, claro, yo creo que eso tendrá que pasar por muchos tests, si volvemos al Optimus, que es uno de los grandes, \ncomo esos exoesqueletos, le quitamos la idea al Masc y que nos invite a algo, si lo hace, pero yo creo que el tema sería ver hasta qué punto, \ndespués de esos tests, por no reventarnos el principio de prudencia, supongo que tendrá que haber una legislación que garantice que no haga \ndaño a la gente. \nDespués, hay otras declaraciones... \nBueno, dentro de la propia declaración de Barcelona se hablaba del tema de la no sé si la traducción, la fiabilidad, quiero decir que el \nsistema tiene que ser seguro, eso es una cosa que tendrá que garantizar la normativa. \nY después había por allá el tema del rol humano, es decir, tiene que haber un rol humano que no se pierda la persona responsable de... o sea, \nquién tiene la responsabilidad, eso también es una cosa esencial, de esta máquina. \nClaro, cuando tú te pones la rodillera o te pones un exoesqueleto, estás asumiendo que tú eres el responsable porque es una extensión de tu \ncuerpo, aunque sea tuneada, pero cuando es una entidad externa, como el coche que decías antes o este robot óptimus o lo que sea, a veces \nno está tan claro, pero tiene que haber también el responsable humano. \nEs como el perro. \nTú tienes un perro, también es un paralelismo un poco así, porque es el vivo, pero si tú tienes un perro peligroso y hace alguna... o no, y hace \nalguna, el amo es el responsable y aquí, si mira, ha mordido a un niño pequeño y le ha metido una herida, escucha, la multa o la cárcel, \nincluso, eres tú el responsable de todo esto. \nY para mí quizás es el tema más relevante. \nIncorporaré en los contenidos la declaración de Barcelona, ahora que me has hecho pensar, y también, y otro melón que hay aquí después, es \ndecir, fíjate que al final Elon Musk relaciona sus empresas. \nUna de las opciones que hay cuando tienes herramientas como Neuralinks es la telepresencia. \nEs decir, un óptimus puede ser un dispositivo de telepresencia. \nSi tenemos... \nFíjate que el señor ya lo hace todo. \nTiene los Starlinks para comunicar los datos, tiene los mecanismos para conectar, para conectar, pues, contra cerebros y tiene el dispositivo \nhumanoide, que quizás si no tienes inteligencia artificial, tú podrías coger y decir \"este aparato lo que está haciendo es simplemente siendo \nun avatar de una persona de verdad\". \nY entonces tú con eso puedes viajar o puedes hacer acciones muy peligrosas y muy precisas, porque lo estás haciendo... \nO sea, digamos que se abren las opciones, las posibilidades y se van más allá. \nNo, no. \nYa digo, aquí, sobre todo el tema de la seguridad también es que, claro, es clave, ¿no? \nPero hay como varios niveles, ¿no? \nYo pienso que el nivel de seguridad industrial de la máquina, eso ya por normativas tendrá que cumplir normativas muy duras, por tanto, ya \nlo tendrán que cumplir. \nY después, un poco, los otros dilemas más éticos que hemos estado hablando un poco, y morales, incluso, pues yo creo que esos son los que, \nbueno, dependiendo de la sociedad, pues en pueden cambiar. \nEl ejemplo paradigmático era el caso de... \nSi tú hacías, cuando se hacían esos tests aquellos de moral mit de conducción, claro, tú aquí, en Europa, dices que es... \nQué prefieres, ¿no? \nQue te daba elegir yo. \nAtropellar una vaca o atropellar... \nY claro, en la India, en cambio, la gente no, no atropelles la vaca. \nNo puedes atropellar la vaca porque es una... \nEs... \nClaro, mejor atropellar a la persona y ya la siguiente reencarnación en esta persona ya tendrá suerte, ¿no? \nYa tendrá suerte, quizás sea una vaca. \nClaro, claro, aquí... \nY bueno, y cosas de estas, también, culturales, hay aspectos culturales que se tienen que tener en cuenta con esta incorporación. \nExcepto, yo creo que la primera fase serán máquinas seguramente para eso, carga-descarga, tareas repetitivas y que... \nY por tanto, será como un machaca que tendrás en casa, jardinero... \nHacer de costureros para Inditex. \nSí, Déu-n'hi-do. \nPuede ser, ¿no? \nHay ciertas tareas que... que quizás no hace falta que hagamos las personas. \nLo que pasa que también, como pasa con todas las cosas, y lo comentábamos el otro día con Ariadna, es decir si cierto... y ciertas personas \nel trabajo es una forma, digamos, de tener, a ver, desde que tenemos la ética protestante de Max Weber, es una forma de estar orgulloso y de \nautorrealizarte y de darte y de dar un propósito a la vida de las personas, pero también es una herramienta de poder político. \nUn trabajador o una trabajadora, solo por el hecho de ser trabajador y trabajadora, tiene un poder político que va más allá del votante. \nEs decir, unas elecciones estás sometido a unas tendencias, publicidad, macroscopía y todo ese tipo de cosas, pero, en cambio, un conjunto \nde trabajadores pueden coger y hacer una presión determinada en un momento determinado solo por ejercer su poder de huelga. \nSi de repente ya no puedes hacer poder, no estás trabajando porque no estás haciendo una contribución real a la sociedad, tu poder de huelga \ndesaparece y de repente ya no se trata de un aspecto económico, sino que se trata de una forma de distribución del poder social. \nClaro, aquí también esas iniciativas privadas lo que a mí me hacen pensar también es un poco en qué una cosa que la Carme Torres decía, \nque tiene que haber iniciativas públicas de inversión en estos sistemas de robótica como en otros temas de IA generativa. \n",
        "kind": "online_pdf",
        "filename": "optimus-e-etico-social.pdf",
        "url": "https://data.llmprimer.com/optimus/optimus-e-etico-social.pdf#page=6"
    },
    {
        "number": 7,
        "title": "Entrevista experto etico social",
        "page": 7,
        "text": "Lo que estamos viendo es que el sector público está muy atrás, quiero decir, yo no sé, pero quizás tú lo sabes mejor, pero los datos creo que \nestaban en el 90-10 de inversión en temas de IA en general y en el caso de la robótica, claro, yo lo que quiero decir es que... \nA ver, hay un economista europeo que se llama Mariana Mazzucato que ella lo que dice es que es totalmente al contrario, es que la gran \ncantidad de inversión sobre todo en ciencia de base, en ciencia fundacional, es inversión pública, lo que pasa es que el último, aquello, el \núltimo kilómetro antes de convertir en producto... \nLa transferencia hace mucha... \n \nEntrevista a experto ética y aspectos sociales pag 7 \n \nLa transferencia, aquella última milla la hace la empresa porque es quien la tiene que hacer, es decir, los investigadores, si un investigador \nque está concentrado en teoría de la señal, una cosa muy específica y está refinando ciertas cosas, está en aquello y no está pensando en \ncómo una cosa se puede productizar. \nEntonces lo que tienes es que hay una gran cantidad de tecnologías que se hacen productivas, pues como... \nA ver, ella, la Mariana Mazzucato, cogió y analizó el iPhone y decía \"el 95% de las tecnologías que están dentro del iPhone son tecnologías \nque se han desarrollado por todo el mundo con ciencia abierta, con presupuestos públicos y que lo que pasa es que la última capa hay una \nempresa que lo junta... \nPero entonces aquí... \nCompro, voy allá porque había un cierto retorno, ya que un cierto retorno a la sociedad y que el impacto social de estas máquinas, pues, \nbueno, intentar volver al tema de la prudencia, controlarlo al máximo, quiero decir que en un momento dado se preservase... \nNo sé, imagina que hay un impacto laboral. \nAhora me lo estoy... \nPero tú en casa tienes tres personas... \nBueno, tú y yo no, pero los que tengo aquí delante, que yo veo la Mola y Matadepera, pues los de Matadepera igual sí que tienen más gente \nde servicio. \nY en un momento dado pueden decir \"mira, puedo comprar un robot de estos y hacer fuera a una persona personal\". \nUn trabajador. \nYo creo que la gente que tiene dinero de verdad en el futuro la asistencia personal, es decir, imagina, o sea, que es... \nYo tengo una Thermomix, ¿de acuerdo? \nSí. \nTengo la Thermomix barata de Amazon, ¿de acuerdo? \nYo tengo la Thermomix barata de Amazon y me va muy bien, me ahorra muchísimo trabajo, pero alguien que tiene realmente dinero tiene \nuna cocinera. \nYa. \nEntiendes? \nYo tengo un Room y tengo una Thermomix y quien tiene dinero de verdad tiene una cocinera y un chófer y una... \nY un robot y un Optimus para que cuando hagas fiestas no se diga que tú no tienes un Optimus. \nSí, pero tú también quieres tener el que tiene dinero de verdad querrá la asistencia humana y al final los que tendré... \nEs decir, si tú te imaginas la cocina de una gente muy rica no tienen un microondas y una Thermomix. \nTendrán unos fogones muy grandes y unas fregaderos muy grandes y unas grandes neveras y cosas y alguien que cocine y que lo limpie \ntodo. \nOtro tema que me ha venido a la mente ahora y que me pensarán personas porque me ha venido a la mente dos cosas. \nHay un tema sobre dilemas éticos. \nEl tema del impacto ambiental en cuanto a la creación de estas máquinas como las baterías. \nYo tengo un tema ambiental que Kate Crawford, la analista de IA lo explica muy bien, yo creo, que la IA en general y más cuando es \nmaterializada parece que vamos por aquí, con robots, tiene un impacto ambiental muy grande, quiero decir, no es aquello del nube y tal. \nEso es un tema a cuestionarnos, quiero decir, si debe haber algún tipo de gravamen como pasa con los coches por ejemplo, pues \ndependiendo de las características, una etiqueta energética o no. \nHay un tema ambiental para mí relevante también aquí y después hay otro tema que también se está hablando mucho que es el tema de los \nentrenamientos de estas máquinas, con qué tipo de datos se han hecho. \nEsos entrenamientos es una propiedad intelectual y se debe tener en cuenta. \nSobre el tema ambiental, el otro día en Xavier Cugat vino al Mosseg a La Poma y nos explicaba que si tú quieres coger y montar una \ninstalación fotovoltaica, no de autoconsumo, una instalación fotovoltaica industrial, digamos, del orden de, digamos, de 5.000 kilovatios, en \nel momento en que tú estás empezando a pensar o a montar una instalación de 500 kilovatios en un pueblo, antes de poder conectar, que te \nden el permiso para tú poder conectar esa instalación, tienes que tener un plan de reciclaje, es decir, de desmantelamiento de todo el plan, es \ndecir, de recuperación ambiental y si eso lo has puesto en una pendiente de una montaña, pues esa, como eso se reconstruye, con una \ndisposición de todos los materiales y con un reciclaje de todos los materiales, que vale decir que en este caso las placas fotovoltaicas son \ncasi 100% reciclables. \nEs decir, una vez tienes ese plan, tienes que depositar en el Ayuntamiento un aval, un aval por el dinero que cuesta ese reciclaje, que se \nactualiza, que se actualiza con el IPC, es decir, cada año, cada año o cada dos años o tres años, se tiene que reevaluar el coste, hay costos \nque bajan, es decir, quizás ciertas cosas, mira, escucha, el reciclaje de esto se ha bajado porque hay más demanda, se actualiza y tienes que \nmantener eso actualizado y no te lo devuelven hasta que no se haya hecho una inspección que compruebe que de aquí 25, 30, 40 años \ncuando se haya acabado esto, esa instalación se ha tenido que dejar, es decir, que tú has de incorporar en los costos de explotación es decir, \nentonces, de la misma manera, ahora me parece que los teléfonos móviles ya empiezan a incorporar, por ejemplo, Apple si dices \"cuando \ncompres el próximo móvil, danos el anterior porque lo reciclamos y entonces te haremos un descuento\", o que es lo que hacíamos antes con \nlas botellas, devuélveme las botellas de agua y de Coca-Cola y te devolveremos los casos, o lo que tenemos en el OPC con el token de las \ntazas de café reciclables. \nEsto se puede coger y incorporar aquí dentro? \nEn cualquier caso estos dispositivos son altísimamente reciclables. \nPorque son aluminio... \nEs un tema a considerar como este decía, dentro del... \nEs un tema poliédrico, seguramente lo que implican estas máquinas y... \n",
        "kind": "online_pdf",
        "filename": "optimus-e-etico-social.pdf",
        "url": "https://data.llmprimer.com/optimus/optimus-e-etico-social.pdf#page=7"
    },
    {
        "number": 8,
        "title": "Entrevista experto etico social",
        "page": 8,
        "text": "Otra cuestión es, volviendo a los datos de los entrenamientos, una cosa que se está diciendo últimamente, el Gano Boni lo dijo en el CCCB \nel otro día en un encuentro, que es que, curiosamente, pero la IA no impacta en la mayor parte de la sociedad, sobre la cual, en cambio, es \nextractivista de datos, porque la IA necesita muchos datos, y esos datos provienen de buena parte de la población que los ha cedido... \nEn el caso paradigmático son las famosas cookies y todo lo que implica la cesión de datos masiva que se está haciendo a la sociedad. \nY, en ese sentido, ya digo, esta máquina se habrá entrenado y se habrá entrenado con muchos datos, igual que ahora se está mirando qué ha \nhecho OpenAI, de dónde vienen los datos de los entrenamientos de los chats GPT y compañía, de los modelos de lenguaje y el tema de los \ndatos también de imagen, de los entrenamientos visuales, en fin, todo eso yo pienso que es otro tema que, si se quieren hacer bien las cosas, \npues deberían considerar los desarrolladores de Optimus y de otras tecnologías. \nPues, Toni, escucha, muchísimas gracias. \nYo creo que con esto lo tenemos. \n \n",
        "kind": "online_pdf",
        "filename": "optimus-e-etico-social.pdf",
        "url": "https://data.llmprimer.com/optimus/optimus-e-etico-social.pdf#page=8"
    }
]